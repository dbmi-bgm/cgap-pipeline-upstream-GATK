## Pipeline information #####################################
#     General information for the pipeline
#############################################################
name: WES_upstream_gatk_proband
description: Pipeline to process paired-end FASTQ files using GATK for Whole Exome Sequencing data. |
             Produce an analysis-ready BAM file. |
             Proband.

## General arguments ########################################
#     Pipeline input, reference files, and general arguments
#       define all arguments for the pipeline here
#############################################################
input:

  # File argument
  fastqs_R1:
    argument_type: file.fastq
    dimensionality: 2

  fastqs_R2:
    argument_type: file.fastq
    dimensionality: 2

  reference_bwa:
    argument_type: file.bwt
    files:
      - complete-reference-bwt@hg38

  reference_fa:
    argument_type: file.fa
    files:
      - complete-reference-fasta@hg38

  known-sites-indels:
    argument_type: file.vcf
    files:
      - mills-1000g-gold-standard-indel@hg38

  known-sites-snp:
    argument_type: file.vcf_gz
    files:
      - dbsnp-common@151

  # Parameter argument
  sample_names:
    argument_type: parameter.json

  eff_genome_size:
    argument_type: parameter.integer
    value: "62847115"

## Workflows and dependencies ###############################
#     Information for the workflows and their dependencies
#############################################################
workflows:

  ## Workflow definition #####################
  #   bwa-mem_no_unzip-check
  ############################################
  bwa-mem_no_unzip-check:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      fastq_R1:
        argument_type: file.fastq
        source_argument_name: fastqs_R1
        scatter: 2

      fastq_R2:
        argument_type: file.fastq
        source_argument_name: fastqs_R2
        scatter: 2

      reference:
        argument_type: file.bwt
        source_argument_name: reference_bwa

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      raw_bam:
        file_type: raw BAM
        description: output from bwa-mem in BAM format
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: c5n.18xlarge
      ebs_size: "6.3x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_bwa-mem_no_unzip-check
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   bamqc@1
  ############################################
  bamqc@1:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bam:
        argument_type: file.bam
        source: bwa-mem_no_unzip-check
        source_argument_name: raw_bam

      # Parameter argument
      sample:
        argument_type: parameter.json
        source_argument_name: sample_names
        input_dimension: 1

      eff_genome_size:
        argument_type: parameter.integer

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: c5a.2xlarge
      ebs_size: "3.5x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_bamqc
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   add-readgroups-check
  ############################################
  add-readgroups-check:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bam:
        argument_type: file.bam
        source: bwa-mem_no_unzip-check
        source_argument_name: raw_bam

      # Parameter argument
      sample_name:
        argument_type: parameter.json
        source_argument_name: sample_names
        input_dimension: 1

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      bam_w_readgroups:
        file_type: intermediate BAM
        description: output from AddReadGroups in BAM format
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: c5a.2xlarge
      ebs_size: "3.5x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_add-readgroups-check
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   merge-bam-check
  ############################################
  merge-bam-check:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bams:
        argument_type: file.bam
        source: add-readgroups-check
        source_argument_name: bam_w_readgroups
        gather: 1

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      merged_bam:
        file_type: intermediate BAM
        description: output from merging step in BAM format
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: c5a.2xlarge
      ebs_size: "3x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_merge-bam-check
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   picard-MarkDuplicates-check
  ############################################
  picard-MarkDuplicates-check:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bam:
        argument_type: file.bam
        source: merge-bam-check
        source_argument_name: merged_bam

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      dupmarked_bam:
        file_type: intermediate BAM
        description: output from MarkDuplicates in BAM format
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: c5n.18xlarge
      ebs_size: "3x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_picard-MarkDuplicates-check
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   sort-bam-check
  ############################################
  sort-bam-check:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bam:
        argument_type: file.bam
        source: picard-MarkDuplicates-check
        source_argument_name: dupmarked_bam

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      sorted_bam:
        file_type: intermediate BAM
        description: output from sorting step in BAM format
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: m5a.2xlarge
      ebs_size: "3.2x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_sort-bam-check
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   gatk-BaseRecalibrator
  ############################################
  gatk-BaseRecalibrator:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bam:
        argument_type: file.bam
        source: sort-bam-check
        source_argument_name: sorted_bam

      reference:
        argument_type: file.fa
        source_argument_name: reference_fa

      known-sites-indels:
        argument_type: file.vcf

      known-sites-snp:
        argument_type: file.vcf_gz

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      recalibration_report:
        file_type: recalibration table
        description: output from BaseRecalibrator in TXT format
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: t3.small
      ebs_size: "2x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_gatk-BaseRecalibrator
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   gatk-ApplyBQSR-check
  ############################################
  gatk-ApplyBQSR-check:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bam:
        argument_type: file.bam
        source: sort-bam-check
        source_argument_name: sorted_bam

      recalibration_report:
        argument_type: file.txt
        source: gatk-BaseRecalibrator

      reference:
        argument_type: file.fa
        source_argument_name: reference_fa

      # Parameter argument
      nthreads:
        argument_type: parameter.integer
        value: "28"

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      recalibrated_bam:
        file_type: analysis-ready BAM
        description: output from ApplyBQSR in BAM format
        linkto_location:
          - Sample
        s3_lifecycle_category: long_term_access_long_term_archive

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: c5n.9xlarge
      ebs_size: "5.5x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_gatk-ApplyBQSR-check
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   bamqc@2
  ############################################
  bamqc@2:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_bam:
        argument_type: file.bam
        source: gatk-ApplyBQSR-check
        source_argument_name: recalibrated_bam

      # Parameter argument
      sample:
        argument_type: parameter.json
        source_argument_name: sample_names
        input_dimension: 1

      eff_genome_size:
        argument_type: parameter.integer

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type: c5a.2xlarge
      ebs_size: "3.5x"
      EBS_optimized: True
      spot_instance: True
      run_name: run_bamqc
      behavior_on_capacity_limit: wait_and_retry
